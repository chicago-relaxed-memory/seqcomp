\RequirePackage{amssymb}  %% bizarre error previous def of Bbbk if after documentclass
\documentclass[acmsmall,screen,anonymous,review]{acmart}\settopmatter{printfolios=true}
\hypersetup{bookmarksnumbered,bookmarksopen=true,bookmarksdepth=3}
\settopmatter{printfolios=true}
\AtEndPreamble{%
  \theoremstyle{acmdefinition}
  \newtheorem{remark}[theorem]{Remark}
  \newtheorem{candidate}[theorem]{Candidate}
  \renewcommand{\theequation}{\fnsymbol{equation}}
}
\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}   %% For author/year citations

\setcopyright{rightsretained}
\acmPrice{}
\acmDOI{}
\acmYear{2022}
\copyrightyear{2022}
\acmSubmissionID{}
\acmJournal{PACMPL}
\acmVolume{0}
\acmNumber{POPL}
\acmArticle{0}
\acmMonth{1}
\startPage{1}

\usepackage{macros}
% \showRAfalse
\showSCOPEfalse
\title{The Leaky Semicolon}


\usepackage{xr}
\externaldocument{paper}
\makecounter{Bkappa} \setcounter{Bkappa}{2}
\makecounter{Btau}   \setcounter{Btau}{3}
\makecounter{Bterm}  \setcounter{Bterm}{4}
\begin{document}
\appendix
\input{oopsla.tex}
\input{discussion.tex}
\input{arm.tex}
\input{drf.tex}
\input{extra.tex}
\bibliography{bib}
\end{document}






































Alex Aiken PLDI keynote:
\begin{itemize}
\item PAD Machines: Parallel, Accelerated (GPUs..), Distributed (memory)
\item ``Registered'' memory: shared with network
\item ``Zero-copy'' memory: shared with GPUs
  \begin{itemize}
  \item
    \url{http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-unified-memory-programming-hd}
    Unified Memory offers a “single-pointer-to-data” model that is
    conceptually similar to CUDA’s zero-copy memory. One key difference
    between the two is that with zero-copy allocations the physical location
    of memory is pinned in CPU system memory such that a program may have
    fast or slow access to it depending on where it is being accessed
    from. Unified Memory, on the other hand, decouples memory and execution
    spaces so that all data accesses are fast.
  \end{itemize}
\item Software manages ``NUMA domains''
\item In PAD machines, most computation happening on the accelerators.
\item Bad Programming models:
  \begin{itemize}
  \item Data Analytics, Machine Learning: Single program in Spark Hadoop,
    Etc.  Accessible to many people, Low performance
  \item HPC: MPI, OpenMP, Vector Intrinsics, Cuda, etc...  Experts only, High performance
  \end{itemize}
\item Task based models are good.
  \begin{itemize}
  \item Asynchronous functions that get mapped to real resources.  May have
    sub-tasks or not.  
  \item Tasks capture locality:
    \begin{itemize}
    \item Task is co-located with its arguments.  
    \item Tasks are a ``local address space'' model.
    \end{itemize}
  \item Tasks capture asynchrony
  \end{itemize}
\item Semantics
  \begin{itemize}
  \item \xmark Explicit Parallelism: X10, Chapel
  \item \cmark Implicit Parallelism (dataflow) --- much easier to reason about
    (sequential semantics) --- automated data movement
    \begin{itemize}
    \item Layout Explicitly programmed: StarPU 
    \item Layout computed statically: PaRSEC/PTG, DPJ, Sequoia
    \item Layout computed dynamically: Legion, PaRSEC/DTD, TensorFlow
    \end{itemize}
  \end{itemize}
\item Partitioning:
  \begin{itemize}
  \item Flat disjoint partitions: TensorFlow, PyTorch.
    \begin{itemize}
    \item Not compositional: Problem is that different parts of the
      application may want different views of the data.
    \end{itemize}
  \end{itemize}
\item Hierarchical: StarPU
  \begin{itemize}
  \item Partitions created/destroyed
  \item Partitions are disjoint
  \item Only one partition of collection at a time
  \item Only leaves can be used by application
  \item Eager Repartitioning move data unnecessarily
  \end{itemize}
\item Legion allows multiple hierarchical partitions
  \begin{itemize}
  \item Compositional: data movement is lazy
  \item Task dependence analysis requires alias analysis
  \end{itemize}
\end{itemize}


% Local Variables:
% mode: latex
% TeX-master: t
% End:
